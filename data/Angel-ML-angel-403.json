{
    "error_id": "403",
    "information": {
        "errors": [
            {
                "line": "11",
                "severity": "error",
                "message": "Line is longer than 100 characters (found 103).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": " * https://opensource.org/licenses/BSD-3-Clause\n *\n * Unless required by applicable law or agreed to in writing, software distributed under the License is\n * distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n * either express or implied. See the License for the specific language governing permissions and\n * limitations under the License.",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/intellij/403/SerdeUtils.java\nindex 9a3b329e4f..1e4feb8f2d 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/intellij/403/SerdeUtils.java\n@@ -34,207 +34,219 @@ import java.util.List;\n  * Serialize/Deserialize tool for training data split.\n  */\n public class SerdeUtils {\n-  private static SerializationFactory factory;\n-\n-  public static SplitClassification deSerilizeSplitProtos(List<SplitInfoProto> splitInfoList,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n-    boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n-    if (isUseNewAPI) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n-      for (SplitInfoProto splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeNewSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n-            .toByteArray(), conf));\n-      }\n-\n-      SplitClassification splits = new SplitClassification(null, splitList, true);\n-      return splits;\n-    } else {\n-      List<org.apache.hadoop.mapred.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n-      for (SplitInfoProto splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeOldSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n-            .toByteArray(), conf));\n-      }\n-\n-      SplitClassification splits = new SplitClassification(splitList, null, true);\n-      return splits;\n+    private static SerializationFactory factory;\n+\n+    public static SplitClassification deSerilizeSplitProtos(List<SplitInfoProto> splitInfoList,\n+                                                            Configuration conf)\n+            throws ClassNotFoundException, IOException {\n+        boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n+        if (isUseNewAPI) {\n+            List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n+                    new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n+            for (SplitInfoProto splitInfo : splitInfoList) {\n+                splitList.add(deSerilizeNewSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n+                        .toByteArray(), conf));\n+            }\n+\n+            SplitClassification splits = new SplitClassification(null, splitList, true);\n+            return splits;\n+        } else {\n+            List<org.apache.hadoop.mapred.InputSplit> splitList =\n+                    new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n+            for (SplitInfoProto splitInfo : splitInfoList) {\n+                splitList.add(deSerilizeOldSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n+                        .toByteArray(), conf));\n+            }\n+\n+            SplitClassification splits = new SplitClassification(splitList, null, true);\n+            return splits;\n+        }\n     }\n-  }\n \n \n-  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-  public static SplitInfo serilizeSplit(org.apache.hadoop.mapreduce.InputSplit split,\n-      Configuration conf) throws IOException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static SplitInfo serilizeSplit(org.apache.hadoop.mapreduce.InputSplit split,\n+                                          Configuration conf) throws IOException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+        DataOutputBuffer out = new DataOutputBuffer(1024);\n+\n+        try {\n+            Serializer serializer = factory.getSerializer(split.getClass());\n+            serializer.open(out);\n+            serializer.serialize(split);\n+            SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n+            return ret;\n+        } finally {\n+            out.close();\n+        }\n     }\n-    DataOutputBuffer out = new DataOutputBuffer(1024);\n-\n-    try {\n-      Serializer serializer = factory.getSerializer(split.getClass());\n-      serializer.open(out);\n-      serializer.serialize(split);\n-      SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n-      return ret;\n-    } finally {\n-      out.close();\n-    }\n-  }\n \n-  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-  public static SplitInfo serilizeSplit(org.apache.hadoop.mapred.InputSplit split,\n-      Configuration conf) throws IOException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n-    }\n-    DataOutputBuffer out = new DataOutputBuffer(1024);\n-\n-    try {\n-      Serializer serializer = factory.getSerializer(split.getClass());\n-      serializer.open(out);\n-      serializer.serialize(split);\n-      SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n-      return ret;\n-    } finally {\n-      out.close();\n-    }\n-  }\n-\n-  public static List<SplitInfo> serilizeSplits(SplitClassification splits, Configuration conf)\n-      throws IOException {\n-\n-    List<SplitInfo> splitInfoList = new ArrayList<SplitInfo>();\n-    if (splits.isUseNewAPI()) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList = splits.getSplitsNewAPI();\n-      for (org.apache.hadoop.mapreduce.InputSplit split : splitList) {\n-        splitInfoList.add(serilizeSplit(split, conf));\n-      }\n-    } else {\n-      List<org.apache.hadoop.mapred.InputSplit> splitList = splits.getSplitsOldAPI();\n-      for (org.apache.hadoop.mapred.InputSplit split : splitList) {\n-        splitInfoList.add(serilizeSplit(split, conf));\n-      }\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static SplitInfo serilizeSplit(org.apache.hadoop.mapred.InputSplit split,\n+                                          Configuration conf) throws IOException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+        DataOutputBuffer out = new DataOutputBuffer(1024);\n+\n+        try {\n+            Serializer serializer = factory.getSerializer(split.getClass());\n+            serializer.open(out);\n+            serializer.serialize(split);\n+            SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n+            return ret;\n+        } finally {\n+            out.close();\n+        }\n     }\n \n-    return splitInfoList;\n-  }\n-\n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(SplitInfo splitInfo,\n-      Configuration conf) throws IOException, ClassNotFoundException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+    public static List<SplitInfo> serilizeSplits(SplitClassification splits, Configuration conf)\n+            throws IOException {\n+\n+        List<SplitInfo> splitInfoList = new ArrayList<SplitInfo>();\n+        if (splits.isUseNewAPI()) {\n+            List<org.apache.hadoop.mapreduce.InputSplit> splitList = splits.getSplitsNewAPI();\n+            for (org.apache.hadoop.mapreduce.InputSplit split : splitList) {\n+                splitInfoList.add(serilizeSplit(split, conf));\n+            }\n+        } else {\n+            List<org.apache.hadoop.mapred.InputSplit> splitList = splits.getSplitsOldAPI();\n+            for (org.apache.hadoop.mapred.InputSplit split : splitList) {\n+                splitInfoList.add(serilizeSplit(split, conf));\n+            }\n+        }\n+\n+        return splitInfoList;\n     }\n \n-    ByteArrayInputStream in = null;\n-\n-    try {\n-      Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n-    } finally {\n-      if (in != null) {\n-        in.close();\n-      }\n-    }\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(SplitInfo splitInfo,\n+                                                                            Configuration conf)\n+            throws IOException, ClassNotFoundException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+\n+        ByteArrayInputStream in = null;\n+\n+        try {\n+            Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n+                    factory.getDeserializer(\n+                            (Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n+                                    .forName(splitInfo.getSplitClass()));\n+            in = new ByteArrayInputStream(splitInfo.getSplit());\n+            deSerializer.open(in);\n+            return deSerializer.deserialize(null);\n+        } finally {\n+            if (in != null) {\n+                in.close();\n+            }\n+        }\n \n-  }\n-\n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(SplitInfo splitInfo,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n-    }\n-\n-    ByteArrayInputStream in = null;\n-\n-    try {\n-      Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n-    } finally {\n-      if (in != null) {\n-        in.close();\n-      }\n-    }\n-  }\n-\n-  public static SplitClassification deSerilizeSplits(List<SplitInfo> splitInfoList,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n-    boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n-    if (isUseNewAPI) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n-      for (SplitInfo splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeNewSplit(splitInfo, conf));\n-      }\n-\n-      SplitClassification splits = new SplitClassification(null, splitList, true);\n-      return splits;\n-    } else {\n-      List<org.apache.hadoop.mapred.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n-      for (SplitInfo splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeOldSplit(splitInfo, conf));\n-      }\n-\n-      SplitClassification splits = new SplitClassification(splitList, null, true);\n-      return splits;\n     }\n-  }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className,\n-      byte[] data, Configuration conf) throws IOException, ClassNotFoundException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(SplitInfo splitInfo,\n+                                                                         Configuration conf)\n+            throws ClassNotFoundException, IOException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+\n+        ByteArrayInputStream in = null;\n+\n+        try {\n+            Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n+                    factory.getDeserializer(\n+                            (Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n+                                    .forName(splitInfo.getSplitClass()));\n+            in = new ByteArrayInputStream(splitInfo.getSplit());\n+            deSerializer.open(in);\n+            return deSerializer.deserialize(null);\n+        } finally {\n+            if (in != null) {\n+                in.close();\n+            }\n+        }\n     }\n \n-    ByteArrayInputStream in = null;\n-\n-    try {\n-      Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n-    } finally {\n-      if (in != null) {\n-        in.close();\n-      }\n+    public static SplitClassification deSerilizeSplits(List<SplitInfo> splitInfoList,\n+                                                       Configuration conf)\n+            throws ClassNotFoundException, IOException {\n+        boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n+        if (isUseNewAPI) {\n+            List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n+                    new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n+            for (SplitInfo splitInfo : splitInfoList) {\n+                splitList.add(deSerilizeNewSplit(splitInfo, conf));\n+            }\n+\n+            SplitClassification splits = new SplitClassification(null, splitList, true);\n+            return splits;\n+        } else {\n+            List<org.apache.hadoop.mapred.InputSplit> splitList =\n+                    new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n+            for (SplitInfo splitInfo : splitInfoList) {\n+                splitList.add(deSerilizeOldSplit(splitInfo, conf));\n+            }\n+\n+            SplitClassification splits = new SplitClassification(splitList, null, true);\n+            return splits;\n+        }\n     }\n \n-  }\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className,\n+                                                                            byte[] data,\n+                                                                            Configuration conf)\n+            throws IOException, ClassNotFoundException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+\n+        ByteArrayInputStream in = null;\n+\n+        try {\n+            Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n+                    factory.getDeserializer(\n+                            (Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n+                                    .forName(className));\n+            in = new ByteArrayInputStream(data);\n+            deSerializer.open(in);\n+            return deSerializer.deserialize(null);\n+        } finally {\n+            if (in != null) {\n+                in.close();\n+            }\n+        }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className,\n-      byte[] data, Configuration conf) throws ClassNotFoundException, IOException {\n-    if (factory == null) {\n-      factory = new SerializationFactory(conf);\n     }\n \n-    ByteArrayInputStream in = null;\n-\n-    try {\n-      Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n-    } finally {\n-      if (in != null) {\n-        in.close();\n-      }\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className,\n+                                                                         byte[] data,\n+                                                                         Configuration conf)\n+            throws ClassNotFoundException, IOException {\n+        if (factory == null) {\n+            factory = new SerializationFactory(conf);\n+        }\n+\n+        ByteArrayInputStream in = null;\n+\n+        try {\n+            Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n+                    factory.getDeserializer(\n+                            (Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n+                                    .forName(className));\n+            in = new ByteArrayInputStream(data);\n+            deSerializer.open(in);\n+            return deSerializer.deserialize(null);\n+        } finally {\n+            if (in != null) {\n+                in.close();\n+            }\n+        }\n     }\n-  }\n }\n",
            "diff_size": 277
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "130",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 134).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "152",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 131).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "189",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 169).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "197",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 118).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "210",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 166).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "218",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 115).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/naturalize/403/SerdeUtils.java\nindex 9a3b329e4f..a725b354c4 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/naturalize/403/SerdeUtils.java\n@@ -38,7 +38,8 @@ public class SerdeUtils {\n \n   public static SplitClassification deSerilizeSplitProtos(List<SplitInfoProto> splitInfoList,\n       Configuration conf) throws ClassNotFoundException, IOException {\n-    boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n+\n+  boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n     if (isUseNewAPI) {\n       List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n           new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n@@ -62,16 +63,14 @@ public class SerdeUtils {\n     }\n   }\n \n-\n-  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n   public static SplitInfo serilizeSplit(org.apache.hadoop.mapreduce.InputSplit split,\n       Configuration conf) throws IOException {\n-    if (factory == null) {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n     DataOutputBuffer out = new DataOutputBuffer(1024);\n-\n-    try {\n+try {\n       Serializer serializer = factory.getSerializer(split.getClass());\n       serializer.open(out);\n       serializer.serialize(split);\n@@ -85,12 +84,11 @@ public class SerdeUtils {\n   @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n   public static SplitInfo serilizeSplit(org.apache.hadoop.mapred.InputSplit split,\n       Configuration conf) throws IOException {\n-    if (factory == null) {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n     DataOutputBuffer out = new DataOutputBuffer(1024);\n-\n-    try {\n+try {\n       Serializer serializer = factory.getSerializer(split.getClass());\n       serializer.open(out);\n       serializer.serialize(split);\n@@ -103,8 +101,7 @@ public class SerdeUtils {\n \n   public static List<SplitInfo> serilizeSplits(SplitClassification splits, Configuration conf)\n       throws IOException {\n-\n-    List<SplitInfo> splitInfoList = new ArrayList<SplitInfo>();\n+  List<SplitInfo> splitInfoList = new ArrayList<SplitInfo>();\n     if (splits.isUseNewAPI()) {\n       List<org.apache.hadoop.mapreduce.InputSplit> splitList = splits.getSplitsNewAPI();\n       for (org.apache.hadoop.mapreduce.InputSplit split : splitList) {\n@@ -123,17 +120,15 @@ public class SerdeUtils {\n   @SuppressWarnings(\"unchecked\")\n   public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(SplitInfo splitInfo,\n       Configuration conf) throws IOException, ClassNotFoundException {\n-    if (factory == null) {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n-    try {\n+try {\n       Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n+          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class.forName(splitInfo.getSplitClass()));\n+in = new ByteArrayInputStream(splitInfo.getSplit());\n       deSerializer.open(in);\n       return deSerializer.deserialize(null);\n     } finally {\n@@ -147,17 +142,15 @@ public class SerdeUtils {\n   @SuppressWarnings(\"unchecked\")\n   public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(SplitInfo splitInfo,\n       Configuration conf) throws ClassNotFoundException, IOException {\n-    if (factory == null) {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n-    try {\n+try {\n       Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n+          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class.forName(splitInfo.getSplitClass()));\n+in = new ByteArrayInputStream(splitInfo.getSplit());\n       deSerializer.open(in);\n       return deSerializer.deserialize(null);\n     } finally {\n@@ -169,7 +162,8 @@ public class SerdeUtils {\n \n   public static SplitClassification deSerilizeSplits(List<SplitInfo> splitInfoList,\n       Configuration conf) throws ClassNotFoundException, IOException {\n-    boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n+\n+  boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n     if (isUseNewAPI) {\n       List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n           new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n@@ -192,19 +186,16 @@ public class SerdeUtils {\n   }\n \n   @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className,\n-      byte[] data, Configuration conf) throws IOException, ClassNotFoundException {\n-    if (factory == null) {\n+  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className, byte[] data, Configuration conf) throws IOException, ClassNotFoundException {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n-    try {\n+try {\n       Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n+          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class.forName(className));\n+in = new ByteArrayInputStream(data);\n       deSerializer.open(in);\n       return deSerializer.deserialize(null);\n     } finally {\n@@ -216,19 +207,16 @@ public class SerdeUtils {\n   }\n \n   @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className,\n-      byte[] data, Configuration conf) throws ClassNotFoundException, IOException {\n-    if (factory == null) {\n+  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className, byte[] data, Configuration conf) throws ClassNotFoundException, IOException {\n+  if (factory == null) {\n       factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n-    try {\n+try {\n       Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n+          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class.forName(className));\n+in = new ByteArrayInputStream(data);\n       deSerializer.open(in);\n       return deSerializer.deserialize(null);\n     } finally {\n@@ -237,4 +225,4 @@ public class SerdeUtils {\n       }\n     }\n   }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 43
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "39",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 160).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "42",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 121).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "44",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 128).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "50",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 113).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "52",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 118).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "61",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 128).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "79",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 125).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "96",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 117).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "113",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 161).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "120",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 210).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "132",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 158).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "139",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 204).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "150",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 150).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "153",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 121).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "161",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 113).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "172",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 171).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "179",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 194).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "191",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 168).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "198",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 188).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/codebuff/403/SerdeUtils.java\nindex 9a3b329e4f..4932f508ae 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/403/SerdeUtils.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/codebuff/403/SerdeUtils.java\n@@ -24,7 +24,6 @@ import org.apache.hadoop.io.DataOutputBuffer;\n import org.apache.hadoop.io.serializer.Deserializer;\n import org.apache.hadoop.io.serializer.SerializationFactory;\n import org.apache.hadoop.io.serializer.Serializer;\n-\n import java.io.ByteArrayInputStream;\n import java.io.IOException;\n import java.util.ArrayList;\n@@ -33,208 +32,177 @@ import java.util.List;\n /**\n  * Serialize/Deserialize tool for training data split.\n  */\n+\n public class SerdeUtils {\n-  private static SerializationFactory factory;\n+    private static SerializationFactory factory;\n \n-  public static SplitClassification deSerilizeSplitProtos(List<SplitInfoProto> splitInfoList,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n+    public static SplitClassification deSerilizeSplitProtos(List<SplitInfoProto> splitInfoList, Configuration conf) throws ClassNotFoundException, IOException {\n     boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n     if (isUseNewAPI) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n-      for (SplitInfoProto splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeNewSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n-            .toByteArray(), conf));\n-      }\n+        List<org.apache.hadoop.mapreduce.InputSplit> splitList = new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n+        for (SplitInfoProto splitInfo : splitInfoList) {\n+                         splitList.add(deSerilizeNewSplit(splitInfo.getSplitClass(), splitInfo.getSplit().toByteArray(), conf));\n+        }\n \n-      SplitClassification splits = new SplitClassification(null, splitList, true);\n-      return splits;\n+        SplitClassification splits = new SplitClassification(null, splitList, true);\n+        return splits;\n     } else {\n-      List<org.apache.hadoop.mapred.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n+      List<org.apache.hadoop.mapred.InputSplit> splitList = new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n       for (SplitInfoProto splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeOldSplit(splitInfo.getSplitClass(), splitInfo.getSplit()\n-            .toByteArray(), conf));\n+               splitList.add(deSerilizeOldSplit(splitInfo.getSplitClass(), splitInfo.getSplit().toByteArray(), conf));\n       }\n \n       SplitClassification splits = new SplitClassification(splitList, null, true);\n       return splits;\n     }\n-  }\n-\n+    }\n \n-  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-  public static SplitInfo serilizeSplit(org.apache.hadoop.mapreduce.InputSplit split,\n-      Configuration conf) throws IOException {\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static SplitInfo serilizeSplit(org.apache.hadoop.mapreduce.InputSplit split, Configuration conf) throws IOException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n-    DataOutputBuffer out = new DataOutputBuffer(1024);\n \n+    DataOutputBuffer out = new DataOutputBuffer(1024);\n     try {\n-      Serializer serializer = factory.getSerializer(split.getClass());\n-      serializer.open(out);\n-      serializer.serialize(split);\n-      SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n-      return ret;\n+        Serializer serializer = factory.getSerializer(split.getClass());\n+        serializer.open(out);\n+        serializer.serialize(split);\n+        SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n+        return ret;\n     } finally {\n       out.close();\n     }\n-  }\n+    }\n \n-  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-  public static SplitInfo serilizeSplit(org.apache.hadoop.mapred.InputSplit split,\n-      Configuration conf) throws IOException {\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static SplitInfo serilizeSplit(org.apache.hadoop.mapred.InputSplit split, Configuration conf) throws IOException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n-    DataOutputBuffer out = new DataOutputBuffer(1024);\n \n+    DataOutputBuffer out = new DataOutputBuffer(1024);\n     try {\n-      Serializer serializer = factory.getSerializer(split.getClass());\n-      serializer.open(out);\n-      serializer.serialize(split);\n-      SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n-      return ret;\n+        Serializer serializer = factory.getSerializer(split.getClass());\n+        serializer.open(out);\n+        serializer.serialize(split);\n+        SplitInfo ret = new SplitInfo(split.getClass().getName(), out.getData());\n+        return ret;\n     } finally {\n       out.close();\n     }\n-  }\n-\n-  public static List<SplitInfo> serilizeSplits(SplitClassification splits, Configuration conf)\n-      throws IOException {\n+    }\n \n+    public static List<SplitInfo> serilizeSplits(SplitClassification splits, Configuration conf) throws IOException {\n     List<SplitInfo> splitInfoList = new ArrayList<SplitInfo>();\n     if (splits.isUseNewAPI()) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList = splits.getSplitsNewAPI();\n-      for (org.apache.hadoop.mapreduce.InputSplit split : splitList) {\n-        splitInfoList.add(serilizeSplit(split, conf));\n-      }\n+        List<org.apache.hadoop.mapreduce.InputSplit> splitList = splits.getSplitsNewAPI();\n+        for (org.apache.hadoop.mapreduce.InputSplit split : splitList) {\n+                                  splitInfoList.add(serilizeSplit(split, conf));\n+        }\n     } else {\n       List<org.apache.hadoop.mapred.InputSplit> splitList = splits.getSplitsOldAPI();\n       for (org.apache.hadoop.mapred.InputSplit split : splitList) {\n-        splitInfoList.add(serilizeSplit(split, conf));\n+               splitInfoList.add(serilizeSplit(split, conf));\n       }\n     }\n-\n     return splitInfoList;\n-  }\n+    }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(SplitInfo splitInfo,\n-      Configuration conf) throws IOException, ClassNotFoundException {\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(SplitInfo splitInfo, Configuration conf) throws IOException, ClassNotFoundException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n     try {\n-      Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n+        Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer = factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class.forName(splitInfo.getSplitClass()));\n+        in = new ByteArrayInputStream(splitInfo.getSplit());\n+        deSerializer.open(in);\n+        return deSerializer.deserialize(null);\n     } finally {\n       if (in != null) {\n         in.close();\n       }\n     }\n+    }\n \n-  }\n-\n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(SplitInfo splitInfo,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(SplitInfo splitInfo, Configuration conf) throws ClassNotFoundException, IOException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n     try {\n-      Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(splitInfo.getSplitClass()));\n-      in = new ByteArrayInputStream(splitInfo.getSplit());\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n+        Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer = factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class.forName(splitInfo.getSplitClass()));\n+        in = new ByteArrayInputStream(splitInfo.getSplit());\n+        deSerializer.open(in);\n+        return deSerializer.deserialize(null);\n     } finally {\n       if (in != null) {\n         in.close();\n       }\n     }\n-  }\n+    }\n \n-  public static SplitClassification deSerilizeSplits(List<SplitInfo> splitInfoList,\n-      Configuration conf) throws ClassNotFoundException, IOException {\n+    public static SplitClassification deSerilizeSplits(List<SplitInfo> splitInfoList, Configuration conf) throws ClassNotFoundException, IOException {\n     boolean isUseNewAPI = conf.getBoolean(\"mapred.mapper.new-api\", false);\n     if (isUseNewAPI) {\n-      List<org.apache.hadoop.mapreduce.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n-      for (SplitInfo splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeNewSplit(splitInfo, conf));\n-      }\n+        List<org.apache.hadoop.mapreduce.InputSplit> splitList = new ArrayList<org.apache.hadoop.mapreduce.InputSplit>();\n+        for (SplitInfo splitInfo : splitInfoList) {\n+                         splitList.add(deSerilizeNewSplit(splitInfo, conf));\n+        }\n \n-      SplitClassification splits = new SplitClassification(null, splitList, true);\n-      return splits;\n+        SplitClassification splits = new SplitClassification(null, splitList, true);\n+        return splits;\n     } else {\n-      List<org.apache.hadoop.mapred.InputSplit> splitList =\n-          new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n+      List<org.apache.hadoop.mapred.InputSplit> splitList = new ArrayList<org.apache.hadoop.mapred.InputSplit>();\n       for (SplitInfo splitInfo : splitInfoList) {\n-        splitList.add(deSerilizeOldSplit(splitInfo, conf));\n+               splitList.add(deSerilizeOldSplit(splitInfo, conf));\n       }\n \n       SplitClassification splits = new SplitClassification(splitList, null, true);\n       return splits;\n     }\n-  }\n+    }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className,\n-      byte[] data, Configuration conf) throws IOException, ClassNotFoundException {\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapreduce.InputSplit deSerilizeNewSplit(String className, byte[] data, Configuration conf) throws IOException, ClassNotFoundException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n     try {\n-      Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n+        Deserializer<? extends org.apache.hadoop.mapreduce.InputSplit> deSerializer = factory.getDeserializer((Class<? extends org.apache.hadoop.mapreduce.InputSplit>) Class.forName(className));\n+        in = new ByteArrayInputStream(data);\n+        deSerializer.open(in);\n+        return deSerializer.deserialize(null);\n     } finally {\n       if (in != null) {\n         in.close();\n       }\n     }\n+    }\n \n-  }\n-\n-  @SuppressWarnings(\"unchecked\")\n-  public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className,\n-      byte[] data, Configuration conf) throws ClassNotFoundException, IOException {\n+    @SuppressWarnings(\"unchecked\")\n+    public static org.apache.hadoop.mapred.InputSplit deSerilizeOldSplit(String className, byte[] data, Configuration conf) throws ClassNotFoundException, IOException {\n     if (factory == null) {\n-      factory = new SerializationFactory(conf);\n+        factory = new SerializationFactory(conf);\n     }\n \n     ByteArrayInputStream in = null;\n-\n     try {\n-      Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer =\n-          factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class\n-              .forName(className));\n-      in = new ByteArrayInputStream(data);\n-      deSerializer.open(in);\n-      return deSerializer.deserialize(null);\n+        Deserializer<? extends org.apache.hadoop.mapred.InputSplit> deSerializer = factory.getDeserializer((Class<? extends org.apache.hadoop.mapred.InputSplit>) Class.forName(className));\n+        in = new ByteArrayInputStream(data);\n+        deSerializer.open(in);\n+        return deSerializer.deserialize(null);\n     } finally {\n       if (in != null) {\n         in.close();\n       }\n     }\n-  }\n-}\n+    }\n+}\n\\ No newline at end of file\n",
            "diff_size": 120
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "11",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ]
}