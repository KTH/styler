{
    "error_id": "882",
    "information": {
        "errors": [
            {
                "line": "6",
                "severity": "error",
                "message": "Line is longer than 100 characters (found 102).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": " * Copyright (C) 2017-2018 THL A29 Limited, a Tencent company. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in\n * compliance with the License. You may obtain a copy of the License at\n *\n * https://opensource.org/licenses/Apache-2.0",
    "results": [
        {
            "tool": "styler",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "intellij",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/intellij/882/AdaDeltaUpdateFunc.java\nindex adf768a5df..82842a5dba 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/intellij/882/AdaDeltaUpdateFunc.java\n@@ -28,66 +28,67 @@ import org.apache.commons.logging.LogFactory;\n \n public class AdaDeltaUpdateFunc extends OptMMUpdateFunc {\n \n-  private static final Log LOG = LogFactory.getLog(AdaDeltaUpdateFunc.class);\n-\n-  public AdaDeltaUpdateFunc() {\n-    super();\n-  }\n-\n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch) {\n-    this(matId, factor, epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, 1);\n-  }\n-\n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n-  }\n-\n-  @Override\n-  public void update(RowBasedPartition partition, int factor, double[] scalars) {\n-    double epsilon = scalars[0];\n-    double alpha = scalars[1];\n-    double beta = scalars[2];\n-    double lr = scalars[3];\n-    double l1RegParam = scalars[4];\n-    double l2RegParam = scalars[5];\n-    double epoch = (int) scalars[6];\n-    double batchSize = (int) scalars[7];\n-\n-    for (int f = 0; f < factor; f++) {\n-      ServerRow gradientServerRow = partition.getRow(f + 3 * factor);\n-      try {\n-        gradientServerRow.startWrite();\n-        Vector weight = ServerRowUtils.getVector(partition.getRow(f));\n-        Vector square1 = ServerRowUtils.getVector(partition.getRow(f + factor));\n-        Vector square2 = ServerRowUtils.getVector(partition.getRow(f + 2 * factor));\n-        Vector gradient = ServerRowUtils.getVector(gradientServerRow);\n-\n-        if (batchSize > 1) {\n-          gradient.idiv(batchSize);\n-        }\n+    private static final Log LOG = LogFactory.getLog(AdaDeltaUpdateFunc.class);\n \n-        OptFuncs.iexpsmoothing2(square1, gradient, alpha);\n-        Vector hessian = OptFuncs.adadeltahessian(square1, square2);\n+    public AdaDeltaUpdateFunc() {\n+        super();\n+    }\n \n-        if (l2RegParam != 0) {\n-          gradient.iaxpy(weight, l2RegParam);\n-        }\n+    public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n+                              double lr, double regL1Param, double regL2Param, int epoch) {\n+        this(matId, factor, epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, 1);\n+    }\n \n-        OptFuncs.iadadeltadelta(gradient, hessian, l2RegParam);\n-        weight.isub(gradient);\n-        OptFuncs.iexpsmoothing2(square2, gradient, beta);\n+    public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n+                              double lr, double regL1Param, double regL2Param, int epoch,\n+                              int batchSize) {\n+        super(matId, new int[] {factor},\n+                new double[] {epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+    }\n \n-        if (l1RegParam != 0) {\n-          OptFuncs.iadadeltathredshold(weight, hessian, l1RegParam, l2RegParam);\n+    @Override\n+    public void update(RowBasedPartition partition, int factor, double[] scalars) {\n+        double epsilon = scalars[0];\n+        double alpha = scalars[1];\n+        double beta = scalars[2];\n+        double lr = scalars[3];\n+        double l1RegParam = scalars[4];\n+        double l2RegParam = scalars[5];\n+        double epoch = (int) scalars[6];\n+        double batchSize = (int) scalars[7];\n+\n+        for (int f = 0; f < factor; f++) {\n+            ServerRow gradientServerRow = partition.getRow(f + 3 * factor);\n+            try {\n+                gradientServerRow.startWrite();\n+                Vector weight = ServerRowUtils.getVector(partition.getRow(f));\n+                Vector square1 = ServerRowUtils.getVector(partition.getRow(f + factor));\n+                Vector square2 = ServerRowUtils.getVector(partition.getRow(f + 2 * factor));\n+                Vector gradient = ServerRowUtils.getVector(gradientServerRow);\n+\n+                if (batchSize > 1) {\n+                    gradient.idiv(batchSize);\n+                }\n+\n+                OptFuncs.iexpsmoothing2(square1, gradient, alpha);\n+                Vector hessian = OptFuncs.adadeltahessian(square1, square2);\n+\n+                if (l2RegParam != 0) {\n+                    gradient.iaxpy(weight, l2RegParam);\n+                }\n+\n+                OptFuncs.iadadeltadelta(gradient, hessian, l2RegParam);\n+                weight.isub(gradient);\n+                OptFuncs.iexpsmoothing2(square2, gradient, beta);\n+\n+                if (l1RegParam != 0) {\n+                    OptFuncs.iadadeltathredshold(weight, hessian, l1RegParam, l2RegParam);\n+                }\n+\n+                gradient.clear();\n+            } finally {\n+                gradientServerRow.endWrite();\n+            }\n         }\n-\n-        gradient.clear();\n-      } finally {\n-        gradientServerRow.endWrite();\n-      }\n     }\n-  }\n }\n",
            "diff_size": 102
        },
        {
            "tool": "naturalize",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "37",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 155).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "41",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 170).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "42",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 118).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/naturalize/882/AdaDeltaUpdateFunc.java\nindex adf768a5df..9e973e67bd 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/naturalize/882/AdaDeltaUpdateFunc.java\n@@ -34,15 +34,12 @@ public class AdaDeltaUpdateFunc extends OptMMUpdateFunc {\n     super();\n   }\n \n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch) {\n-    this(matId, factor, epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, 1);\n+  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta, double lr, double regL1Param, double regL2Param, int epoch) {\n+  this(matId, factor, epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, 1);\n   }\n \n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta, double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n+    super(matId, new int[]{factor}, new double[]{epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n   }\n \n   @Override\n@@ -90,4 +87,4 @@ public class AdaDeltaUpdateFunc extends OptMMUpdateFunc {\n       }\n     }\n   }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 8
        },
        {
            "tool": "codebuff",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "46",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 172).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "66",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "67",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 113).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "68",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 117).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "69",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 103).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "74",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 101).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/codebuff/882/AdaDeltaUpdateFunc.java\nindex adf768a5df..4f1322d4e4 100644\n--- a/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/errored/1/882/AdaDeltaUpdateFunc.java\n+++ b/home/thomas/mnt/fernanda/styler-test2/python/./experiments/projects/../results/Angel-ML-angel/codebuff/882/AdaDeltaUpdateFunc.java\n@@ -19,7 +19,6 @@ package com.tencent.angel.ml.psf.optimizer;\n \n import com.tencent.angel.ml.math2.ufuncs.OptFuncs;\n import com.tencent.angel.ml.math2.vector.Vector;\n-\n import com.tencent.angel.ps.storage.partition.RowBasedPartition;\n import com.tencent.angel.ps.storage.vector.ServerRow;\n import com.tencent.angel.ps.storage.vector.ServerRowUtils;\n@@ -27,26 +26,31 @@ import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n \n public class AdaDeltaUpdateFunc extends OptMMUpdateFunc {\n+    private static final Log LOG = LogFactory.getLog(AdaDeltaUpdateFunc.class);\n \n-  private static final Log LOG = LogFactory.getLog(AdaDeltaUpdateFunc.class);\n-\n-  public AdaDeltaUpdateFunc() {\n+    public AdaDeltaUpdateFunc() {\n     super();\n-  }\n+    }\n \n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch) {\n+    public AdaDeltaUpdateFunc(int matId,\n+                              int factor,\n+                              double epsilon,\n+                              double alpha,\n+                              double beta,\n+                              double lr,\n+                              double regL1Param,\n+                              double regL2Param, int epoch) {\n     this(matId, factor, epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, 1);\n-  }\n+    }\n \n-  public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta,\n-      double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n-  }\n+    public AdaDeltaUpdateFunc(int matId, int factor, double epsilon, double alpha, double beta, double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n+    super(matId,\n+new int[]{factor},\n+new double[]{epsilon, alpha, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+    }\n \n-  @Override\n-  public void update(RowBasedPartition partition, int factor, double[] scalars) {\n+    @Override\n+    public void update(RowBasedPartition partition, int factor, double[] scalars) {\n     double epsilon = scalars[0];\n     double alpha = scalars[1];\n     double beta = scalars[2];\n@@ -55,39 +59,33 @@ public class AdaDeltaUpdateFunc extends OptMMUpdateFunc {\n     double l2RegParam = scalars[5];\n     double epoch = (int) scalars[6];\n     double batchSize = (int) scalars[7];\n-\n     for (int f = 0; f < factor; f++) {\n-      ServerRow gradientServerRow = partition.getRow(f + 3 * factor);\n-      try {\n-        gradientServerRow.startWrite();\n-        Vector weight = ServerRowUtils.getVector(partition.getRow(f));\n-        Vector square1 = ServerRowUtils.getVector(partition.getRow(f + factor));\n-        Vector square2 = ServerRowUtils.getVector(partition.getRow(f + 2 * factor));\n-        Vector gradient = ServerRowUtils.getVector(gradientServerRow);\n-\n-        if (batchSize > 1) {\n-          gradient.idiv(batchSize);\n-        }\n-\n-        OptFuncs.iexpsmoothing2(square1, gradient, alpha);\n-        Vector hessian = OptFuncs.adadeltahessian(square1, square2);\n-\n-        if (l2RegParam != 0) {\n-          gradient.iaxpy(weight, l2RegParam);\n-        }\n-\n-        OptFuncs.iadadeltadelta(gradient, hessian, l2RegParam);\n-        weight.isub(gradient);\n-        OptFuncs.iexpsmoothing2(square2, gradient, beta);\n-\n-        if (l1RegParam != 0) {\n-          OptFuncs.iadadeltathredshold(weight, hessian, l1RegParam, l2RegParam);\n+        ServerRow gradientServerRow = partition.getRow(f + 3 * factor);\n+        try {\n+                                         gradientServerRow.startWrite();\n+                                         Vector weight = ServerRowUtils.getVector(partition.getRow(f));\n+                                         Vector square1 = ServerRowUtils.getVector(partition.getRow(f + factor));\n+                                         Vector square2 = ServerRowUtils.getVector(partition.getRow(f + 2 * factor));\n+                                         Vector gradient = ServerRowUtils.getVector(gradientServerRow);\n+                                         if (batchSize > 1) {\n+            gradient.idiv(batchSize);\n+                                         }\n+                                         OptFuncs.iexpsmoothing2(square1, gradient, alpha);\n+                                         Vector hessian = OptFuncs.adadeltahessian(square1, square2);\n+                                         if (l2RegParam != 0) {\n+            gradient.iaxpy(weight, l2RegParam);\n+                                         }\n+                                         OptFuncs.iadadeltadelta(gradient, hessian, l2RegParam);\n+                                         weight.isub(gradient);\n+                                         OptFuncs.iexpsmoothing2(square2, gradient, beta);\n+                                         if (l1RegParam != 0) {\n+            OptFuncs.iadadeltathredshold(weight, hessian, l1RegParam, l2RegParam);\n+                                         }\n+                                         gradient.clear();\n+        } finally {\n+          gradientServerRow.endWrite();\n         }\n-\n-        gradient.clear();\n-      } finally {\n-        gradientServerRow.endWrite();\n-      }\n     }\n-  }\n-}\n+    }\n+\n+}\n\\ No newline at end of file\n",
            "diff_size": 56
        },
        {
            "tool": "styler_random",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "errors": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ]
}